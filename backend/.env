# ========================
# Environment Variables Configuration
# ========================
# All environment variables are optional except:
# 1. The LLM provider you plan to use → you must set only that provider’s key(s).
# 2. Model configuration → you should define at least the default models you want.
# 3. The secret key for LiteLLM (LITELLM_MASTER_KEY) → required for secure communication with the LiteLLM proxy.
#
# Everything else has default values or is not mandatory.
#
# It is also necessary to configure for docker-compose.yml:
# 1. The backend port (BACKEND_PORT)
# 2. The LiteLLM proxy URL (PROXY_URI)
# 3. The database connection details (DATABASE_*)

# ========================
# Backend Configuration
# ========================

# Port for the NestJS backend server (default: 3000)
# BACKEND_PORT=3000

# URL of your LiteLLM proxy (default: http://localhost:4000)
# PROXY_URI=http://litellm:4000

# Secret key for LiteLLM
# LITELLM_MASTER_KEY=<your_master_key>

# ========================
# JWT Authentication
# ========================

# Secret key for signing Access Tokens (default value exists)
# It is strongly recommended to set your own secure value instead of using the default.
# JWT_SECRET=<your_access_token_secret>

# Secret key for signing Refresh Tokens (default value exists)
# It is strongly recommended to set your own secure value instead of using the default.
# JWT_REFRESH_SECRET=<your_refresh_token_secret>


# ========================
# Default Admin User
# ========================

# Initial admin username (default: admin)
# DEFAULT_ADMIN_USERNAME=

# Initial admin email (default: admin@admin.com)
# DEFAULT_ADMIN_EMAIL=

# Initial admin password (default: admin)
# DEFAULT_ADMIN_PASSWORD=

# ========================
# Database Configuration
# ========================

# PostgreSQL database host (default: localhost)
# DATABASE_HOST=db

# PostgreSQL port (default: 5432)
# DATABASE_PORT=5432

# PostgreSQL username (default: postgres)
# DATABASE_USERNAME=user

# PostgreSQL password (default: admin)
# DATABASE_PASSWORD=password

# Database name (default: chatwords)
# DATABASE_NAME=chatwords


# ========================
# LLM Provider API Keys
# (Only set the providers you plan to use)
# ========================

# Amazon Bedrock (requires both access key ID and secret key)
# AMAZON_BEDROCK_ACCESS_KEY_ID=
# AMAZON_BEDROCK_SECRET_ACCESS_KEY=

# Anthropic (Claude models)
# ANTHROPIC_API_KEY=

# AssemblyAI (speech-to-text / audio models)
# ASSEMBLYAI_API_KEY=

# Azure OpenAI (requires both base URL and API key)
# AZURE_API_BASE_URL=
# AZURE_API_KEY=

# Cohere (language models)
# COHERE_API_KEY=

# Cerebras (LLMs on Cerebras Cloud)
# CEREBRAS_API_KEY=

# Databricks (LLM endpoints)
# DATABRICKS_API_KEY=

# Deepgram (speech recognition)
# DEEPGRAM_API_KEY=

# DeepSeek (language models)
# DEEPSEEK_API_KEY=

# ElevenLabs (text-to-speech)
# ELEVENLABS_API_KEY=

# Fireworks.ai (LLM hosting)
# FIREWORKS_API_KEY=

# Google AI Studio (Gemini models)
# GOOGLE_API_KEY=

# Groq (fast LLM inference)
# GROQ_API_KEY=

# Mistral (Open-weight models)
# MISTRAL_API_KEY=

# Ollama (local models, requires base URL)
# OLLAMA_API_BASE_URL=

# OpenAI (GPT models)
# OPENAI_API_KEY=

# OpenRouter (multi-provider API gateway)
# OPENROUTER_API_KEY=

# Perplexity (search + AI API)
# PERPLEXITY_API_KEY=

# SambaNova (enterprise LLMs)
# SAMBANOVA_API_KEY=

# Together AI (LLM hosting platform)
# TOGETHER_API_KEY=

# ========================
# Model Configuration
# ========================

# Each provider "name" MUST be one of the following valid options:
# [
#   "Amazon Bedrock", "Anthropic", "AssemblyAI", "Azure", "Cerebras",
#   "Cohere", "Databricks", "Deepgram", "Deepseek", "ElevenLabs",
#   "Fireworks AI", "Google AI Studio", "Groq", "Mistral AI", "Ollama",
#   "OpenAI", "Openrouter", "Perplexity", "Sambanova", "TogetherAI",
#   "Triton", "xAI"
# ]

# Important Notes:
# - The `name` field must strictly match one of the above providers.
# - The `model` field must exactly match the model identifiers registered and
#   supported by LiteLLM (e.g., "gpt-4", "claude-3-sonnet", "groq/llama-3.3-70b-versatile").
# - Each provider requires its corresponding API key (or access credentials).
#   Make sure the API key is provided if the provider requires it.
# - Multiple models can be defined for the same provider by creating
#   multiple entries with the same "name" but different "model" values.
# - Example: MODELS=[{"providerName":"OpenAI","name":"gpt-4"},{"providerName":"OpenAI","name":"gpt-3.5"}]

# MODELS=